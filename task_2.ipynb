{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2:**\n",
        "\n",
        "**Problem Statement:**\n",
        "Develop a prefix language model using Hugging Face and PyTorch. You can pick any dataset for a creative text generation task and you should report the perplexity metric. Hint: A subtle data preprocessing trick is required when setting the inputs and labels for implementing prefix LM.\n",
        "\n",
        "**Model Selected:** t5-large\n",
        "\n",
        "**Dataset Selected:** CNN daily mail"
      ],
      "metadata": {
        "id": "esvN08agdyAS"
      },
      "id": "esvN08agdyAS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation of Required Packages"
      ],
      "metadata": {
        "id": "aOgP-D4meDLY"
      },
      "id": "aOgP-D4meDLY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d1775b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:46:58.137526Z",
          "iopub.status.busy": "2024-01-20T17:46:58.137135Z",
          "iopub.status.idle": "2024-01-20T17:49:14.434159Z",
          "shell.execute_reply": "2024-01-20T17:49:14.432565Z"
        },
        "papermill": {
          "duration": 136.307628,
          "end_time": "2024-01-20T17:49:14.436676",
          "exception": false,
          "start_time": "2024-01-20T17:46:58.129048",
          "status": "completed"
        },
        "tags": [],
        "id": "34d1775b",
        "outputId": "52445173-c402-417e-d50b-cd8a1f7d623d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.36.2 in /opt/conda/lib/python3.10/site-packages (4.36.2)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (3.12.2)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.20.2)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (1.24.3)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (6.0.1)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2023.8.8)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (2.31.0)\r\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.15.0)\r\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (0.4.1)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.36.2) (4.66.1)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2023.12.2)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.5.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.36.2) (3.0.9)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.2.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.36.2) (2023.11.17)\r\n",
            "Requirement already satisfied: accelerate==0.25.0 in /opt/conda/lib/python3.10/site-packages (0.25.0)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (1.24.3)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (21.3)\r\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (5.9.3)\r\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (6.0.1)\r\n",
            "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (2.0.0)\r\n",
            "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (0.20.2)\r\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.25.0) (0.4.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.25.0) (3.0.9)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (4.5.0)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.2)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.25.0) (2023.12.2)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.25.0) (2.31.0)\r\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.25.0) (4.66.1)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (2.1.3)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.2.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2023.11.17)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\r\n",
            "Collecting datasets==2.15.0\r\n",
            "  Obtaining dependency information for datasets==2.15.0 from https://files.pythonhosted.org/packages/e2/cf/db41e572d7ed958e8679018f8190438ef700aeb501b62da9e1eed9e4d69a/datasets-2.15.0-py3-none-any.whl.metadata\r\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (1.24.3)\r\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (11.0.0)\r\n",
            "Collecting pyarrow-hotfix (from datasets==2.15.0)\r\n",
            "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\r\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.3.7)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.0.3)\r\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.31.0)\r\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (4.66.1)\r\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.4.1)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.70.15)\r\n",
            "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets==2.15.0)\r\n",
            "  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\r\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.8.5)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.20.2)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (6.0.1)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (23.1.0)\r\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (3.2.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (6.0.4)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (4.0.3)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.9.2)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.4.0)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.3.1)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.5.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15.0) (3.0.9)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (2023.11.17)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.3)\r\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.3)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.16.0)\r\n",
            "Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
            "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: pyarrow-hotfix, fsspec, datasets\r\n",
            "  Attempting uninstall: fsspec\r\n",
            "    Found existing installation: fsspec 2023.12.2\r\n",
            "    Uninstalling fsspec-2023.12.2:\r\n",
            "      Successfully uninstalled fsspec-2023.12.2\r\n",
            "  Attempting uninstall: datasets\r\n",
            "    Found existing installation: datasets 2.1.0\r\n",
            "    Uninstalling datasets-2.1.0:\r\n",
            "      Successfully uninstalled datasets-2.1.0\r\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
            "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
            "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
            "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
            "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\r\n",
            "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
            "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
            "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
            "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
            "dask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
            "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\r\n",
            "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
            "dask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
            "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\r\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\r\n",
            "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\r\n",
            "raft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\r\n",
            "s3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
            "\u001b[0mSuccessfully installed datasets-2.15.0 fsspec-2023.10.0 pyarrow-hotfix-0.6\r\n",
            "Collecting peft==0.7.1\r\n",
            "  Obtaining dependency information for peft==0.7.1 from https://files.pythonhosted.org/packages/8b/1b/aee2a330d050c493642d59ba6af51f3910cb138ea48ede228c84c204a5af/peft-0.7.1-py3-none-any.whl.metadata\r\n",
            "  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (1.24.3)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (21.3)\r\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (5.9.3)\r\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (6.0.1)\r\n",
            "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (2.0.0)\r\n",
            "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (4.36.2)\r\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (4.66.1)\r\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (0.25.0)\r\n",
            "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (0.4.1)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.7.1) (0.20.2)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (3.12.2)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2023.10.0)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (2.31.0)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.7.1) (4.5.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.7.1) (3.0.9)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.1) (3.1.2)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.7.1) (2023.8.8)\r\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.7.1) (0.15.0)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.7.1) (2.1.3)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.2.0)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.1) (2023.11.17)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.7.1) (1.3.0)\r\n",
            "Downloading peft-0.7.1-py3-none-any.whl (168 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: peft\r\n",
            "Successfully installed peft-0.7.1\r\n",
            "Collecting bitsandbytes==0.41.3\r\n",
            "  Obtaining dependency information for bitsandbytes==0.41.3 from https://files.pythonhosted.org/packages/1b/db/1a3c0d3542484806c273e8027a328b12be69c1042bb9e134efe93ddf9b50/bitsandbytes-0.41.3-py3-none-any.whl.metadata\r\n",
            "  Downloading bitsandbytes-0.41.3-py3-none-any.whl.metadata (9.8 kB)\r\n",
            "Downloading bitsandbytes-0.41.3-py3-none-any.whl (92.6 MB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\r\n",
            "Successfully installed bitsandbytes-0.41.3\r\n",
            "Collecting trl==0.7.7\r\n",
            "  Obtaining dependency information for trl==0.7.7 from https://files.pythonhosted.org/packages/e8/c2/4c27977024023c762564ab74f8ac39cbf04b8e886300cde1f5a59a5e9573/trl-0.7.7-py3-none-any.whl.metadata\r\n",
            "  Downloading trl-0.7.7-py3-none-any.whl.metadata (10 kB)\r\n",
            "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (2.0.0)\r\n",
            "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (4.36.2)\r\n",
            "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (1.24.3)\r\n",
            "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (0.25.0)\r\n",
            "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.7.7) (2.15.0)\r\n",
            "Collecting tyro>=0.5.11 (from trl==0.7.7)\r\n",
            "  Obtaining dependency information for tyro>=0.5.11 from https://files.pythonhosted.org/packages/96/b4/467ae1bb12b2e7fd71262a19b1b4a83cadd59826ad8f444cfa3fab89f634/tyro-0.6.6-py3-none-any.whl.metadata\r\n",
            "  Downloading tyro-0.6.6-py3-none-any.whl.metadata (7.7 kB)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (4.5.0)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.7.7) (3.1.2)\r\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (0.20.2)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (6.0.1)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (2023.8.8)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (2.31.0)\r\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (0.15.0)\r\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (0.4.1)\r\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.7.7) (4.66.1)\r\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.7) (0.15)\r\n",
            "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.7) (13.5.2)\r\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl==0.7.7)\r\n",
            "  Obtaining dependency information for shtab>=1.5.6 from https://files.pythonhosted.org/packages/40/ad/7227da64498eaa7abecee4311008f70869e156014b3270cec36e2e70cd31/shtab-1.6.5-py3-none-any.whl.metadata\r\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl.metadata (7.3 kB)\r\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.7.7) (5.9.3)\r\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (11.0.0)\r\n",
            "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (0.6)\r\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (0.3.7)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (2.0.3)\r\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (3.4.1)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (0.70.15)\r\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (2023.10.0)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.7) (3.8.5)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (23.1.0)\r\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (3.2.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (6.0.4)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (4.0.3)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (1.9.2)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (1.4.0)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.7) (1.3.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.7.7) (3.0.9)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (3.4)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (1.26.15)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.7.7) (2023.11.17)\r\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.7) (3.0.0)\r\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.7) (2.16.1)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.7.7) (2.1.3)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.7) (2.8.2)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.7) (2023.3)\r\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.7) (2023.3)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.7.7) (1.3.0)\r\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.7) (0.1.2)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.7) (1.16.0)\r\n",
            "Downloading trl-0.7.7-py3-none-any.whl (139 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading tyro-0.6.6-py3-none-any.whl (79 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading shtab-1.6.5-py3-none-any.whl (13 kB)\r\n",
            "Installing collected packages: shtab, tyro, trl\r\n",
            "Successfully installed shtab-1.6.5 trl-0.7.7 tyro-0.6.6\r\n",
            "Requirement already satisfied: tqdm==4.66.1 in /opt/conda/lib/python3.10/site-packages (4.66.1)\r\n",
            "Collecting flash-attn==2.4.2\r\n",
            "  Downloading flash_attn-2.4.2.tar.gz (2.4 MB)\r\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
            "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (2.0.0)\r\n",
            "Collecting einops (from flash-attn==2.4.2)\r\n",
            "  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\r\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (21.3)\r\n",
            "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (1.11.1.1)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->flash-attn==2.4.2) (3.0.9)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.12.2)\r\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (4.5.0)\r\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (1.12)\r\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1)\r\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1.2)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.4.2) (2.1.3)\r\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.4.2) (1.3.0)\r\n",
            "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\r\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\r\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
            "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113935202 sha256=738d0ba133f067ea30a5aa8d85e35f83d4e65467b13693e2d04bf86312f78990\r\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\r\n",
            "Successfully built flash-attn\r\n",
            "Installing collected packages: einops, flash-attn\r\n",
            "Successfully installed einops-0.7.0 flash-attn-2.4.2\r\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.36.2\n",
        "!pip install accelerate==0.25.0\n",
        "!pip install datasets==2.15.0\n",
        "!pip install peft==0.7.1\n",
        "!pip install bitsandbytes==0.41.3\n",
        "!pip install trl==0.7.7\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install flash-attn==2.4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "xFpt4baqeGZs"
      },
      "id": "xFpt4baqeGZs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dea5c4",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-01-20T17:46:56.762800Z",
          "iopub.status.busy": "2024-01-20T17:46:56.762396Z",
          "iopub.status.idle": "2024-01-20T17:46:58.118186Z",
          "shell.execute_reply": "2024-01-20T17:46:58.117312Z"
        },
        "papermill": {
          "duration": 1.367331,
          "end_time": "2024-01-20T17:46:58.120676",
          "exception": false,
          "start_time": "2024-01-20T17:46:56.753345",
          "status": "completed"
        },
        "tags": [],
        "id": "f3dea5c4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "from kaggle_secrets import UserSecretsClient\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments,BartTokenizer, BartForConditionalGeneration"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authentication and Configuration\n",
        "> Huggingface and wandb integration"
      ],
      "metadata": {
        "id": "j6st0t0leIp-"
      },
      "id": "j6st0t0leIp-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea872b88",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:49:14.479211Z",
          "iopub.status.busy": "2024-01-20T17:49:14.478818Z",
          "iopub.status.idle": "2024-01-20T17:49:15.565839Z",
          "shell.execute_reply": "2024-01-20T17:49:15.564660Z"
        },
        "papermill": {
          "duration": 1.111731,
          "end_time": "2024-01-20T17:49:15.568820",
          "exception": false,
          "start_time": "2024-01-20T17:49:14.457089",
          "status": "completed"
        },
        "tags": [],
        "id": "ea872b88",
        "outputId": "045c0b44-3c65-4356-e2df-17d9b42ac699"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "user_secrets = UserSecretsClient()\n",
        "\n",
        "login(token=user_secrets.get_secret(\"HUGGINGFACE_TOKEN_2\"))\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"]=user_secrets.get_secret(\"WANDB_API_KEY_2\")\n",
        "os.environ[\"WANDB_PROJECT\"] = \"Prefix language modelling\"\n",
        "os.environ[\"WANDB_NOTES\"] = \"Prefix language modelling using LORA\"\n",
        "os.environ[\"WANDB_NAME\"] = \"Prefix tuning\"\n",
        "os.environ[\"MODEL_NAME\"] = \"t5-large\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accelerate Memory Estimation\n",
        "> This command estimates the memory requirements for the specified model using the Accelerate library."
      ],
      "metadata": {
        "id": "iu65KpNFeR3-"
      },
      "id": "iu65KpNFeR3-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e3453f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:49:38.308500Z",
          "iopub.status.busy": "2024-01-20T17:49:38.307595Z",
          "iopub.status.idle": "2024-01-20T17:49:46.751759Z",
          "shell.execute_reply": "2024-01-20T17:49:46.750583Z"
        },
        "papermill": {
          "duration": 8.468262,
          "end_time": "2024-01-20T17:49:46.754709",
          "exception": false,
          "start_time": "2024-01-20T17:49:38.286447",
          "status": "completed"
        },
        "tags": [],
        "id": "8e3453f8",
        "outputId": "871e4b19-51d2-427c-e4c0-76c3ab69424e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained config for `t5-large` from `transformers`...\r\n",
            "config.json: 100%|█████████████████████████| 1.21k/1.21k [00:00<00:00, 6.46MB/s]\r\n",
            "┌────────────────────────────────────────────────────┐\r\n",
            "│        Memory Usage for loading `t5-large`         │\r\n",
            "├───────┬─────────────┬──────────┬───────────────────┤\r\n",
            "│ dtype │Largest Layer│Total Size│Training using Adam│\r\n",
            "├───────┼─────────────┼──────────┼───────────────────┤\r\n",
            "│float32│   125.5 MB  │ 2.75 GB  │      10.99 GB     │\r\n",
            "│float16│   62.75 MB  │ 1.37 GB  │       5.5 GB      │\r\n",
            "│  int8 │   31.38 MB  │ 703.5 MB │      2.75 GB      │\r\n",
            "│  int4 │   15.69 MB  │351.75 MB │      1.37 GB      │\r\n",
            "└───────┴─────────────┴──────────┴───────────────────┘\r\n"
          ]
        }
      ],
      "source": [
        "!accelerate estimate-memory ${MODEL_NAME} --library_name transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Quantization Configuration\n",
        "> configures model quantization settings, including whether to load in 4-bit, the quantization type, and data types."
      ],
      "metadata": {
        "id": "kXhSELvOeX77"
      },
      "id": "kXhSELvOeX77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a678a90",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:49:46.799394Z",
          "iopub.status.busy": "2024-01-20T17:49:46.799015Z",
          "iopub.status.idle": "2024-01-20T17:49:46.808462Z",
          "shell.execute_reply": "2024-01-20T17:49:46.807419Z"
        },
        "papermill": {
          "duration": 0.034222,
          "end_time": "2024-01-20T17:49:46.810623",
          "exception": false,
          "start_time": "2024-01-20T17:49:46.776401",
          "status": "completed"
        },
        "tags": [],
        "id": "6a678a90"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "from accelerate import Accelerator\n",
        "import torch\n",
        "\n",
        "load_in_4bit = True\n",
        "\n",
        "if load_in_4bit:\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=load_in_4bit,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16  # Change to torch.float16 for fp16\n",
        "    )\n",
        "    # copy the model to each device\n",
        "    device_map = \"auto\"\n",
        "    torch_dtype = torch.float16  # Change to torch.float16 for fp16\n",
        "else:\n",
        "    device_map = None\n",
        "    quantization_config = None\n",
        "    torch_dtype = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Loading Dataset"
      ],
      "metadata": {
        "id": "UFW2LUYVeeen"
      },
      "id": "UFW2LUYVeeen"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "369b16cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:49:46.854104Z",
          "iopub.status.busy": "2024-01-20T17:49:46.853728Z",
          "iopub.status.idle": "2024-01-20T17:50:31.172403Z",
          "shell.execute_reply": "2024-01-20T17:50:31.171339Z"
        },
        "papermill": {
          "duration": 44.34289,
          "end_time": "2024-01-20T17:50:31.174603",
          "exception": false,
          "start_time": "2024-01-20T17:49:46.831713",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "424647e8cc854d81b864fd22945aa148",
            "9c885a98ebb342fd88abbc92da819a07",
            "5747094f711a46e8875ebbf0b0ab10ea",
            "58bfb1b972ed47308c59fae6cb09c533",
            "f8e4ded8c8674f58b8768812ede11849",
            "f0d3e292a4ff4d349b070c272d5a25d0",
            "df32c20b0e9e458f84bd90271f7426fe",
            "74befbc9937d4afab198da988442424a",
            "9690560bb87349ed9234faec3896506b",
            "289eee24c4c341898bc312b5441232fc",
            "1438c67dc3824ee5aa99e26fe80ec238"
          ]
        },
        "id": "369b16cb",
        "outputId": "bf0a0950-4985-44d1-cb65-8a77cb72eb97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "424647e8cc854d81b864fd22945aa148",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c885a98ebb342fd88abbc92da819a07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5747094f711a46e8875ebbf0b0ab10ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58bfb1b972ed47308c59fae6cb09c533",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8e4ded8c8674f58b8768812ede11849",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0d3e292a4ff4d349b070c272d5a25d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df32c20b0e9e458f84bd90271f7426fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74befbc9937d4afab198da988442424a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9690560bb87349ed9234faec3896506b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "289eee24c4c341898bc312b5441232fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1438c67dc3824ee5aa99e26fe80ec238",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('cnn_dailymail','3.0.0',split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a8765f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:31.220465Z",
          "iopub.status.busy": "2024-01-20T17:50:31.220146Z",
          "iopub.status.idle": "2024-01-20T17:50:31.227688Z",
          "shell.execute_reply": "2024-01-20T17:50:31.226684Z"
        },
        "papermill": {
          "duration": 0.032826,
          "end_time": "2024-01-20T17:50:31.229863",
          "exception": false,
          "start_time": "2024-01-20T17:50:31.197037",
          "status": "completed"
        },
        "tags": [],
        "id": "d7a8765f",
        "outputId": "3ad0b16b-5f60-4c4d-fa74-2c096ad5bdd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['article', 'highlights', 'id'],\n",
              "    num_rows: 287113\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5c695e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:31.319230Z",
          "iopub.status.busy": "2024-01-20T17:50:31.318779Z",
          "iopub.status.idle": "2024-01-20T17:50:31.937013Z",
          "shell.execute_reply": "2024-01-20T17:50:31.936165Z"
        },
        "papermill": {
          "duration": 0.687188,
          "end_time": "2024-01-20T17:50:31.939574",
          "exception": false,
          "start_time": "2024-01-20T17:50:31.252386",
          "status": "completed"
        },
        "tags": [],
        "id": "4c5c695e"
      },
      "outputs": [],
      "source": [
        "dataset= dataset.shuffle(seed=42).select([i for i in range(85000)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c18b757e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:31.987673Z",
          "iopub.status.busy": "2024-01-20T17:50:31.987324Z",
          "iopub.status.idle": "2024-01-20T17:50:32.087663Z",
          "shell.execute_reply": "2024-01-20T17:50:32.086816Z"
        },
        "papermill": {
          "duration": 0.126993,
          "end_time": "2024-01-20T17:50:32.089935",
          "exception": false,
          "start_time": "2024-01-20T17:50:31.962942",
          "status": "completed"
        },
        "tags": [],
        "id": "c18b757e"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.train_test_split(test_size=0.1,seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12b4e374",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:32.136696Z",
          "iopub.status.busy": "2024-01-20T17:50:32.136398Z",
          "iopub.status.idle": "2024-01-20T17:50:32.142304Z",
          "shell.execute_reply": "2024-01-20T17:50:32.141430Z"
        },
        "papermill": {
          "duration": 0.031687,
          "end_time": "2024-01-20T17:50:32.144555",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.112868",
          "status": "completed"
        },
        "tags": [],
        "id": "12b4e374",
        "outputId": "5c79c0a5-7973-45c2-f4f3-af03898afa13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 76500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 8500\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a72c4a11",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:32.190763Z",
          "iopub.status.busy": "2024-01-20T17:50:32.190487Z",
          "iopub.status.idle": "2024-01-20T17:50:32.196053Z",
          "shell.execute_reply": "2024-01-20T17:50:32.195189Z"
        },
        "papermill": {
          "duration": 0.03122,
          "end_time": "2024-01-20T17:50:32.197998",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.166778",
          "status": "completed"
        },
        "tags": [],
        "id": "a72c4a11"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "\n",
        "device = \"cuda\"\n",
        "model_name_or_path = \"t5-large\"\n",
        "tokenizer_name_or_path = \"t5-large\"\n",
        "\n",
        "text_column = \"article\"\n",
        "label_column = \"highlights\"\n",
        "max_length = 256\n",
        "lr = 1e-5\n",
        "num_epochs = 1\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Preprocessing"
      ],
      "metadata": {
        "id": "0dkiP7aReh7b"
      },
      "id": "0dkiP7aReh7b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75238bc8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:32.244870Z",
          "iopub.status.busy": "2024-01-20T17:50:32.244597Z",
          "iopub.status.idle": "2024-01-20T17:50:32.969601Z",
          "shell.execute_reply": "2024-01-20T17:50:32.968524Z"
        },
        "papermill": {
          "duration": 0.751841,
          "end_time": "2024-01-20T17:50:32.972637",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.220796",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "3da27ce917784243a5f44a1390178a98",
            "d963e19dc8ed4bd39bb60f27664d1dcb"
          ]
        },
        "id": "75238bc8",
        "outputId": "02fba73c-8826-424b-cffd-f05296076f0f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3da27ce917784243a5f44a1390178a98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d963e19dc8ed4bd39bb60f27664d1dcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[text_column]\n",
        "    targets = examples[label_column]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    labels = tokenizer(targets, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "    labels = labels[\"input_ids\"]\n",
        "    labels[labels == tokenizer.pad_token_id] = -100\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d340ac8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:50:33.021224Z",
          "iopub.status.busy": "2024-01-20T17:50:33.020846Z",
          "iopub.status.idle": "2024-01-20T17:56:12.481904Z",
          "shell.execute_reply": "2024-01-20T17:56:12.480700Z"
        },
        "papermill": {
          "duration": 339.487833,
          "end_time": "2024-01-20T17:56:12.484479",
          "exception": false,
          "start_time": "2024-01-20T17:50:32.996646",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "e3dc2a77cf9e46688f7848be666c4e37",
            "1a0d386514c54700a100a7a3b11c68d0"
          ]
        },
        "id": "2d340ac8",
        "outputId": "42817a3a-e5ab-4530-fdd8-2e492b4137c9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3dc2a77cf9e46688f7848be666c4e37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/76500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a0d386514c54700a100a7a3b11c68d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running tokenizer on dataset:   0%|          | 0/8500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "processed_datasets = dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=1,\n",
        "    remove_columns=dataset[\"train\"].column_names,\n",
        "    load_from_cache_file=False,\n",
        "    desc=\"Running tokenizer on dataset\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d0aa9d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:12.534269Z",
          "iopub.status.busy": "2024-01-20T17:56:12.533905Z",
          "iopub.status.idle": "2024-01-20T17:56:12.538546Z",
          "shell.execute_reply": "2024-01-20T17:56:12.537593Z"
        },
        "papermill": {
          "duration": 0.031576,
          "end_time": "2024-01-20T17:56:12.540626",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.509050",
          "status": "completed"
        },
        "tags": [],
        "id": "9d0aa9d4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import default_data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686b5ebd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:12.589823Z",
          "iopub.status.busy": "2024-01-20T17:56:12.589543Z",
          "iopub.status.idle": "2024-01-20T17:56:12.595032Z",
          "shell.execute_reply": "2024-01-20T17:56:12.594085Z"
        },
        "papermill": {
          "duration": 0.032596,
          "end_time": "2024-01-20T17:56:12.597034",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.564438",
          "status": "completed"
        },
        "tags": [],
        "id": "686b5ebd"
      },
      "outputs": [],
      "source": [
        "train_dataset = processed_datasets[\"train\"]\n",
        "eval_dataset = processed_datasets[\"test\"]\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
        ")\n",
        "eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prefix Language Model Configuration\n",
        "> Since we are doing Text summarization task, we will use **AutoModelForSeq2SeqLM**"
      ],
      "metadata": {
        "id": "Ee4k5fqSeuLu"
      },
      "id": "Ee4k5fqSeuLu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e3516d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:12.645011Z",
          "iopub.status.busy": "2024-01-20T17:56:12.644711Z",
          "iopub.status.idle": "2024-01-20T17:56:12.649418Z",
          "shell.execute_reply": "2024-01-20T17:56:12.648524Z"
        },
        "papermill": {
          "duration": 0.031131,
          "end_time": "2024-01-20T17:56:12.651524",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.620393",
          "status": "completed"
        },
        "tags": [],
        "id": "08e3516d"
      },
      "outputs": [],
      "source": [
        "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ca1fec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:12.699935Z",
          "iopub.status.busy": "2024-01-20T17:56:12.699651Z",
          "iopub.status.idle": "2024-01-20T17:56:30.059659Z",
          "shell.execute_reply": "2024-01-20T17:56:30.058163Z"
        },
        "papermill": {
          "duration": 17.387135,
          "end_time": "2024-01-20T17:56:30.062217",
          "exception": false,
          "start_time": "2024-01-20T17:56:12.675082",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "2322dd73c7e342c4850c545f8af7b244",
            "aa514efe720240c89cc1a2d4b4438749"
          ]
        },
        "id": "23ca1fec",
        "outputId": "fd0ba740-7fbe-4a39-8e39-74edd10770be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2322dd73c7e342c4850c545f8af7b244",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa514efe720240c89cc1a2d4b4438749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 983,040 || all params: 738,651,136 || trainable%: 0.13308583065659835\n"
          ]
        }
      ],
      "source": [
        "peft_config = PrefixTuningConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, num_virtual_tokens=20)\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718cad56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:30.121770Z",
          "iopub.status.busy": "2024-01-20T17:56:30.121328Z",
          "iopub.status.idle": "2024-01-20T17:56:30.138386Z",
          "shell.execute_reply": "2024-01-20T17:56:30.137343Z"
        },
        "papermill": {
          "duration": 0.050008,
          "end_time": "2024-01-20T17:56:30.141488",
          "exception": false,
          "start_time": "2024-01-20T17:56:30.091480",
          "status": "completed"
        },
        "tags": [],
        "id": "718cad56"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1645a46e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:30.201450Z",
          "iopub.status.busy": "2024-01-20T17:56:30.200708Z",
          "iopub.status.idle": "2024-01-20T17:56:30.218581Z",
          "shell.execute_reply": "2024-01-20T17:56:30.217477Z"
        },
        "papermill": {
          "duration": 0.050613,
          "end_time": "2024-01-20T17:56:30.220885",
          "exception": false,
          "start_time": "2024-01-20T17:56:30.170272",
          "status": "completed"
        },
        "tags": [],
        "id": "1645a46e"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer Initialization and Training"
      ],
      "metadata": {
        "id": "4ONaOXIie71J"
      },
      "id": "4ONaOXIie71J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dd620fa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T17:56:30.271714Z",
          "iopub.status.busy": "2024-01-20T17:56:30.270897Z",
          "iopub.status.idle": "2024-01-20T21:31:04.758423Z",
          "shell.execute_reply": "2024-01-20T21:31:04.757367Z"
        },
        "papermill": {
          "duration": 12874.516015,
          "end_time": "2024-01-20T21:31:04.761031",
          "exception": false,
          "start_time": "2024-01-20T17:56:30.245016",
          "status": "completed"
        },
        "tags": [],
        "id": "9dd620fa",
        "outputId": "69efeeb2-1358-4648-fafb-3ef7d765d362"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maravindsriraj\u001b[0m (\u001b[33maravindan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240120_175633-cqc8xj40\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mPrefix tuning\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aravindan/Prefix%20language%20modelling\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aravindan/Prefix%20language%20modelling/runs/cqc8xj40\u001b[0m\n",
            "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4782' max='4782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4782/4782 3:20:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 13:54]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 2.928058624267578, 'eval_runtime': 835.7248, 'eval_samples_per_second': 10.171, 'eval_steps_per_second': 0.637, 'epoch': 1.0}\n"
          ]
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./output\",\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    save_steps=len(train_dataloader),\n",
        "    save_total_limit=5,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=lr,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=len(train_dataloader),\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=len(train_dataloader),\n",
        "    load_best_model_at_end=True,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "# Create the Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=default_data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print the results\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity Calculation"
      ],
      "metadata": {
        "id": "rps4xWwZe-IK"
      },
      "id": "rps4xWwZe-IK"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def perplexity(eval_output):\n",
        "    return np.exp(eval_output)"
      ],
      "metadata": {
        "id": "H175jOpz07Rl"
      },
      "execution_count": null,
      "outputs": [],
      "id": "H175jOpz07Rl"
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity(results['eval_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVxUG7VA3MJd",
        "outputId": "81df8961-c039-4ccf-e199-eb55e8530fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.691308398129227"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "id": "ZVxUG7VA3MJd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Upload to Hugging Face Model Hub"
      ],
      "metadata": {
        "id": "BV8PltzQfA9R"
      },
      "id": "BV8PltzQfA9R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73facfab",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T21:31:04.810347Z",
          "iopub.status.busy": "2024-01-20T21:31:04.809994Z",
          "iopub.status.idle": "2024-01-20T21:31:06.328723Z",
          "shell.execute_reply": "2024-01-20T21:31:06.327845Z"
        },
        "papermill": {
          "duration": 1.545801,
          "end_time": "2024-01-20T21:31:06.330554",
          "exception": false,
          "start_time": "2024-01-20T21:31:04.784753",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "659bd8244379472ca82adcee87c89841",
            "734c117e0d664a51ae4be504583c1c8f",
            "9c056e267c6648858f70cd6f34071a2c"
          ]
        },
        "id": "73facfab",
        "outputId": "5bb1a58d-78e7-413b-c7cd-2586041fd30d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "659bd8244379472ca82adcee87c89841",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "training_args.bin:   0%|          | 0.00/4.35k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "734c117e0d664a51ae4be504583c1c8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c056e267c6648858f70cd6f34071a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/3.93M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/tr-aravindan/output/commit/518f484be84a25b15c0cfa672f29093906661655', commit_message='t5-large_PREFIX_TUNING_SEQ2SEQ', commit_description='', oid='518f484be84a25b15c0cfa672f29093906661655', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "peft_model_id = \"t5-large_PREFIX_TUNING_SEQ2SEQ\"\n",
        "trainer.push_to_hub(\"t5-large_PREFIX_TUNING_SEQ2SEQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ab8d03",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T21:31:06.381524Z",
          "iopub.status.busy": "2024-01-20T21:31:06.380586Z",
          "iopub.status.idle": "2024-01-20T21:31:07.895927Z",
          "shell.execute_reply": "2024-01-20T21:31:07.894959Z"
        },
        "papermill": {
          "duration": 1.543014,
          "end_time": "2024-01-20T21:31:07.898187",
          "exception": false,
          "start_time": "2024-01-20T21:31:06.355173",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "823db84cf32c4e2386ede945f81cc443"
          ]
        },
        "id": "c0ab8d03",
        "outputId": "a2cfc8ba-7a8b-4da3-b5e7-b0a9b1290907"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "823db84cf32c4e2386ede945f81cc443",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/tr-aravindan/t5-large_PREFIX_TUNING_SEQ/commit/69f4ac8b1c070e022d5e1737188db2376c1000f5', commit_message='Upload tokenizer', commit_description='', oid='69f4ac8b1c070e022d5e1737188db2376c1000f5', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.push_to_hub('t5-large_PREFIX_TUNING_SEQ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading PEFT Model for Text Generation"
      ],
      "metadata": {
        "id": "5gGwjBNafC2R"
      },
      "id": "5gGwjBNafC2R"
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType,PeftConfig,PeftModel\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup\n",
        "\n",
        "peft_model_name=\"tr-aravindan/output\"\n",
        "\n",
        "peft_config=PeftConfig.from_pretrained(peft_model_name)\n",
        "base_model=AutoModelForSeq2SeqLM.from_pretrained(peft_config.base_model_name_or_path)\n",
        "\n",
        "peft_model=PeftModel.from_pretrained(base_model, peft_model_name)"
      ],
      "metadata": {
        "id": "REvhH3D8y1YL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "REvhH3D8y1YL"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(peft_config.base_model_name_or_path)"
      ],
      "metadata": {
        "id": "uSl9YNrD-Pu4"
      },
      "execution_count": null,
      "outputs": [],
      "id": "uSl9YNrD-Pu4"
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "SAN FRANCISCO, California (CNN) -- A magnitude 4.2 earthquake shook the San Francisco area Friday at 4:42 a.m. PT (7:42 a.m. ET), the U.S. Geological Survey reported. The quake left about 2,000 customers without power, said David Eisenhower, a spokesman for Pacific Gas and Light. Under the USGS classification, a magnitude 4.2 earthquake is considered \"light,\" which it says usually causes minimal damage. \"We had quite a spike in calls, mostly calls of inquiry, none of any injury, none of any damage that was reported,\" said Capt. Al Casciato of the San Francisco police. \"It was fairly mild.\" Watch police describe concerned calls immediately after the quake » . The quake was centered about two miles east-northeast of Oakland, at a depth of 3.6 miles, the USGS said. Oakland is just east of San Francisco, across San Francisco Bay. An Oakland police dispatcher told CNN the quake set off alarms at people's homes. The shaking lasted about 50 seconds, said CNN meteorologist Chad Myers. According to the USGS, magnitude 4.2 quakes are felt indoors and may break dishes and windows and overturn unstable objects. Pendulum clocks may stop. E-mail to a friend .\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4kMbw0Bg9k7C"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4kMbw0Bg9k7C"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text,return_tensors='pt')"
      ],
      "metadata": {
        "id": "KRqE4H978DWo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "KRqE4H978DWo"
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "CALQzI68-qC8"
      },
      "execution_count": null,
      "outputs": [],
      "id": "CALQzI68-qC8"
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    outputs = peft_model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=30)\n",
        "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpwjakGd-OWE",
        "outputId": "8bc97c70-6b1e-4d0f-c4c1-4becf7b9a903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['. The quake was centered in the San Francisco Bay Area, the USGS says. about 2,000 customers without power, Pacific']\n"
          ]
        }
      ],
      "id": "vpwjakGd-OWE"
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30636,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 13459.163797,
      "end_time": "2024-01-20T21:31:11.029816",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-01-20T17:46:51.866019",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}